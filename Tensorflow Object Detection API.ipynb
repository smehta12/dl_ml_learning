{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API Experiences on Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tensorflow object detection API(ODA) is one of the several ways to detect the objects in the images. It is built on the top of the TensorFlow that should make it easy to construct, train and deploy object detection models.\n",
    "\n",
    "In this article, I am not going into the great details of the steps to train the model using the ODA but some of the challanges/errors I ran into and what can be the solutions for that. To understand the steps to train models following articles can be helpful.\n",
    "\n",
    "https://www.kdnuggets.com/2018/02/building-toy-detector-tensorflow-object-detection-api.html \n",
    "https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9\n",
    "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_pets.md \n",
    "https://pythonprogramming.net/introduction-use-tensorflow-object-detection-api-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge #1: Find a data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to learn about ODA, the first decision is to make whether to use a dataset which is already labeled or create your own dataset. Based on the posts above, **first I decided to find a unlabeled images and label it by hand** to get an experience.\n",
    "\n",
    "So I started looking into several datasets as listed below:\n",
    "\n",
    "* CVOnline List of Dataset (http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm)\n",
    "* UCI Data sets (https://archive.ics.uci.edu/ml/datasets/)\n",
    "* CV Papers (http://www.cvpapers.com/datasets.html)\n",
    "\n",
    "From the CVOnline, I've find out MIT CBCL Street Scenes data(http://cbcl.mit.edu/software-datasets/streetscenes/). \n",
    "After downloading that, I've started labeling them using the [LabelImg](https://tzutalin.github.io/labelImg/) as suggested in the tutorials. \n",
    "\n",
    "The LabelImg is a very handle tool and annotations are created in the Pascal VOC format. This is the format required by the Tensoflow ODA to convert them into the TfRecodrd format. I'll describe later what's TfRecord format. ![Create BBox Using LableImg](img/Creating_Bbox.PNG) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accroding to the tutorials above you need at least 250-300 annotated images for decent object detection. So when I started annotating this images, it started taking lot of time and due to the lack of enough time, I'd stopped this activity. **Now I decided to get the  dataset with the annotation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When searching on the internet to get the the images with the Annotations, I found following dataset.\n",
    "\n",
    "* COCO (http://cocodataset.org/)\n",
    "* Google's Open Images dataset (https://storage.googleapis.com/openimages/web/index.html)\n",
    "* Pascal VOC (http://host.robots.ox.ac.uk/pascal/VOC/)\n",
    "* KITTI (http://www.cvlibs.net/datasets/kitti/)\n",
    "\n",
    "Among all above, I **chose Pascal VOC**. Because it is a small dataset compare to all other. Also, it comes with the labeling format which the ODA can consume. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge #2: Install the ODA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The installation of the ODA is straightforward but it came up with couple of issues. I've installed on the Windows, Anaconda 2 and the Python 3.6.5.\n",
    "\n",
    "Following are the steps at high level ([Official Steps](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)):\n",
    "\n",
    "1. Install Tensorflow by following [Tensorflow Install Instruction](https://www.tensorflow.org/install/)\n",
    "2. Install following packages.\n",
    "    + pip install --user Cython\n",
    "    + pip install --user contextlib2\n",
    "    + pip install --user pillow\n",
    "    + pip install --user lxml\n",
    "    + pip install --user jupyter\n",
    "    + pip install --user matplotlib\n",
    "3. Check out the [Tensoflow model repo](https://github.com/tensorflow/models)\n",
    "4. Download the [ProtoBuf Compiler](https://github.com/protocolbuffers/protobuf/releases) based on the environment. For windows, it will come up with the .exe to compile the Protobufs.\n",
    "    * Using the downloaded protoc.exe compile protos from in /models/research/object_detection/protos as below.\n",
    "    * Run From /models/research/\n",
    "    > protoc object_detection/protos/*.proto --python_out=.\n",
    "5. Add libraries to PYTHONPATH\n",
    "    > export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
    "    \n",
    "**Issue #1:** In step 4, the  protoc command didn't work for all the files at a same time. So, created individual commands for each files in object_detection/protos as below:\n",
    "\n",
    "    + protoc-3.6.1-win32\\bin\\protoc.exe object_detection\\protos\\argmax_matcher.proto --python_out=.\n",
    "    + protoc-3.6.1-win32\\bin\\protoc.exe object_detection\\protos\\bipartite_matcher.proto --python_out=.\n",
    "    + protoc-3.6.1-win32\\bin\\protoc.exe object_detection\\protos\\box_coder.proto --python_out=.\n",
    "\n",
    "**Issue #2:** The **PYTHONPATH env var is MUST** as in step 5. If it is not set then it will generate errors when the training is started. The only addition of the /models/research/object_detection won't be suffice as the above tutorial suggest.\n",
    "\n",
    "**Issue #3:** The official docs suggest that to use the COCO evaluation metrics copyt pycocotools dir into the /models/research/. But on Windows the `make` command won't work and merely copying the pycocotools will generate the error like **ImportError: No module named _mask**. So here, follow the instructions on [COCO API on Win with Py3](https://github.com/philferriere/cocoapi).  It will compile and install the library in the python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge #3: Creating TFR datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the model on custom dataset the Tensorflow requires data in the Tensorflow Record(TFR) set. It is quite easy provided script. But before creating TFRecords, if we want to detect a perticular type of object from dataset then it needs to be filtered out. In my experiment, I chose **airplane** dataset from Pascal VOC.\n",
    "\n",
    "\n",
    "#### Script to Filter Out airplane dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "\n",
    "object='aeroplane' # Type of obj to determine\n",
    "data_type='train' # Converting train or val data?\n",
    "noise_perc=0.8 # Percentage of noise images out of more than 16000 total images.\n",
    "\n",
    "img_set_list=r\"C:\\my_projects\\tensorflow_obj_detection\\object_detection\\VOCdevkit\\VOC2012\\ImageSets\\Main\\\\\" + object +\"_\" + data_type + \".txt\"\n",
    "img_set_final_list=r\"C:\\my_projects\\tensorflow_obj_detection\\object_detection\\VOCdevkit\\VOC2012\\ImageSets\\Main\\\\\" + object +\"_only_\" + data_type + \".txt\"\n",
    "\n",
    "img_set_file=open(img_set_list, 'r')\n",
    "dest_img_set_file=open(img_set_final_list, 'w')\n",
    "print(img_set_final_list)\n",
    "\n",
    "all_imgs=img_set_file.readlines()\n",
    "total_imgs=len(all_imgs)\n",
    "total_noise_imgs=(total_imgs*noise_img_perc)/100\n",
    "noise_imgs_cnt=0\n",
    "final_imgs=[]\n",
    "print(total_noise_imgs)\n",
    "\n",
    "for img in all_imgs:\n",
    "    t= img.split()\n",
    "    name=t[0]\n",
    "    is_obj=t[1] # Is the item related to class?\n",
    "    if int(is_obj)==1:\n",
    "        print(name)\n",
    "        final_imgs.append(name+'\\n')\n",
    "    elif noise_imgs_cnt<total_noise_imgs:\n",
    "        print(\"noise:%s\"%(name))\n",
    "        final_imgs.append(name+'\\n')\n",
    "        noise_imgs_cnt+=1\n",
    "\n",
    "\n",
    "random.shuffle(final_imgs)\n",
    "dest_img_set_file.write(\"\".join(final_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to convert filtered dataset to the TF record sets.\n",
    "\n",
    "\n",
    "The Tensorflow provides several sample scripts in `models\\research\\object_detection\\dataset_tools\\create_*_tf_record.py`. It is provides the scripts for the well-known datasets like kitti, coco, google open image data set etc. \n",
    "\n",
    "In my experiements case, I used the create_pascal_tf_record.py. I'd set the flags as below for my datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.set = 'val'\n",
    "FLAGS.year='VOC2012'\n",
    "FLAGS.data_dir= r\"C:\\my_projects\\tensorflow_obj_detection\\object_detection\\VOCdevkit\\VOC2012\"\n",
    "FLAGS.output_path=r\"C:\\my_projects\\tensorflow_obj_detection\\object_detection\\tfrecords_voc2012\\plane_val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the command as below for airplane data from Pascal VOC 2012 dataset. \n",
    "\n",
    "* For Training:\n",
    "`C:\\my_projects\\tensorflow\\models\\research> python object_detection\\dataset_tools\\create_pascal_tf_record.py --data_dir=C:\\\\data\\\\VOCdevkit --year=VOC2012 --set=train --output_path=C:\\\\my_prj\\\\obj_detection\\\\data\\\\airplanes_train.record`\n",
    "\n",
    "* For Val:\n",
    "`C:\\my_projects\\tensorflow\\models\\research> python object_detection\\dataset_tools\\create_pascal_tf_record.py --data_dir=C:\\\\data\\\\VOCdevkit --year=VOC2012 --set=val --output_path=C:\\\\my_prj\\\\obj_detection\\\\data\\\\airplanes_val.record`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Info:\n",
    "\n",
    "The Tensorflow requires class label info as below. In my case, I've only 1 class to detect so it will look like as below. I've save in the `C:\\\\my_prj\\\\obj_detection\\\\data\\\\my_class_label.pbtxt`\n",
    "\n",
    "`\n",
    "item {\n",
    "  id: 1\n",
    "  name: 'aeroplane'\n",
    "}\n",
    "`\n",
    "\n",
    "For multiple classes, the above records should be comma separated. There're many examples available in `models\\research\\object_detection\\data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the TFR datasets are created, then first you need to decide if you will use an existing model and fine tune it or build from scratch. It is advisable to use the pre-trained models as it can take less time for training and most of the features that are learnt by CNNs are often object agnostic. \n",
    "\n",
    "Tensorflow provides several pre-trained models. The list of models, speed and accuracy can be seen at [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)\n",
    "\n",
    "For my project, I've chose `ssd_mobilenet_v1_coco` model. In order use it, download the zip file. Unzip it and copy `model.ckpt.*` files in the `C:\\\\my_prj\\\\obj_detection\\\\data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the model training requires a config file where the model can be fine tuned and the paths of all the files above can be specified. The config files for all the models is available at `models\\research\\object_detection\\samples\\configs`. \n",
    "\n",
    "**Caution 1:** Choose the same model config file as the model chosen in the previous step. In my case I chose `ssd_mobilenet_v1_coco_my.config`.\n",
    "\n",
    "Copy this file to `C:\\\\my_prj\\\\obj_detection\\\\data`. Now modify this file. Change the `PATH_TO_BE_CONFIGURED` at all the places. \n",
    "\n",
    "For example, under `train_input_reader` give the `input_path` to the `airplanes_train.record` and for the `label_map_path` provide path to the `.pbtext`. Similarly for the `eval_input_reader`. The path to `label_map_path` will be same as training.\n",
    "\n",
    "Also, don't forget to change `num_classes`.\n",
    "\n",
    "**Caution 2**: For `fine_tune_checkpoint`, DO NOT change the extension for the model.ckpt. Here, Provide the path to the file `model.ckpt.data-00000-of-00001`\n",
    "\n",
    "**Caution 3**: Change the `num_steps` under `train_config`. By default it comes with 200000 steps.\n",
    "\n",
    "In my example case, the dir path to the all of above will be `C:\\\\my_prj\\\\obj_detection\\\\data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the directory `C:\\\\my_prj\\\\obj_detection\\\\data` should have following files:\n",
    "\n",
    "+ ssd_mobilenet_v1_coco_my.config\n",
    "+ aeroplane_train.record\n",
    "+ aeroplane_val.record\n",
    "+ my_class_label.pbtxt\n",
    "+ model.ckpt.data-00000-of-00001\n",
    "+ model.ckpt.index\n",
    "+ model.ckpt.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,we can start the training with the following command:\n",
    "\n",
    "> C:\\my_projects\\tensorflow\\models\\research>python object_detection/model_main.py \n",
    "--pipeline_config_path=C:\\my_projects\\tensorflow_obj_detection\\object_detection\\data\\ssd_mobilenet_v1_coco_my.config --model_dir=C:\\my_projects\\tensorflow_obj_detection\\object_detection\\train_output \\\n",
    "--num_train_steps=100  --sample_1_of_n_eval_examples=1  --alsologtostderr\n",
    "\n",
    "Here, `model_dir` is output of the training where the model checkpints and logs will be stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Issue #1:** During the training, on the python3.6 you may run into the error as below. \n",
    "\n",
    "> TypeError: can't pickle dict_values objects [[Node: PyFunc_3 = PyFunc[Tin=[], Tout=[DT_FLOAT], token=\"pyfunc_5\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
    "\n",
    "The fix for the issue will be find a code snippet as below in `models\\research\\object_detection\\model_lib_orig.py` \n",
    "\n",
    "`# Eval metrics on a single example.\n",
    "eval_metric_ops = eval_util.get_eval_metric_ops_for_evaluators(\n",
    "eval_config, list(category_index.values()), eval_dict)`\n",
    "\n",
    "Remove list casting of the `category_index.values()`. [Ref to the Solution](https://github.com/tensorflow/models/issues/4780)\n",
    "\n",
    "Then restart the training again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is started, start the tensorboard to monitor the progress. Run the following command on another command line.\n",
    "\n",
    "> tensorboard --logdir=C:\\my_projects\\tensorflow_obj_detection\\checkpoints\n",
    "\n",
    "Open the printed URL on browser and check the progress. As the number of iterations increases, precision should go up and the loss should go down as figures in below. \n",
    "\n",
    "![Precision Progress over Itrations](img/precision_progress.PNG)\n",
    "\n",
    "![Loss Reduction over Iterations](img/loss_progress.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training completes, aeroplane should be detected as follow\n",
    "\n",
    "![Plane 1](img/plane1.png)\n",
    "![Plane 2](img/plane2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
